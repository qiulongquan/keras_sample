import tensorflow as tf

# Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(4).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64)).repeat()
validation_dataset = tf.data.Dataset.range(2)

# A feedable iterator is defined by a handle placeholder and its structure. We
# could use the `output_types` and `output_shapes` properties of either
# `training_dataset` or `validation_dataset` here, because they have
# identical structure.
handle = tf.placeholder(tf.string, shape=[])
iterator = tf.data.Iterator.from_string_handle(
    handle, training_dataset.output_types, training_dataset.output_shapes)
next_element = iterator.get_next()

# You can use feedable iterators with a variety of different kinds of iterator
# (such as one-shot and initializable iterators).
training_iterator = training_dataset.make_one_shot_iterator()
validation_iterator = validation_dataset.make_initializable_iterator()

sess = tf.Session()
# The `Iterator.string_handle()` method returns a tensor that can be evaluated
# and used to feed the `handle` placeholder.
training_handle = sess.run(training_iterator.string_handle())
validation_handle = sess.run(validation_iterator.string_handle())

# Loop forever, alternating between training and validation.
while True:
  # Run 200 steps using the training dataset. Note that the training dataset is
  # infinite, and we resume from where we left off in the previous `while` loop
  # iteration.
  for _ in range(4):
    value = sess.run(next_element, feed_dict={handle: training_handle})
    # training_handle: 0, type <class 'numpy.int64'>
    print("training_handle: %s,type: %s" % (value, type(value)))

  # Run one pass over the validation dataset.
  sess.run(validation_iterator.initializer)
  for _ in range(2):
    value = sess.run(next_element, feed_dict={handle: validation_handle})
    # validation_handle: 0,type: <class 'numpy.int64'>
    print("validation_handle: %s,type: %s" % (value, type(value)))

  print("*"*50)
